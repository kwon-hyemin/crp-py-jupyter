{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset, info = tfds.load(\"fashion_mnist\", split=\"train\", with_info=True)\n",
    "\n",
    "def convert(row):\n",
    "    image = tf.image.convert_image_dtype(row[\"image\"], tf.float32)\n",
    "    label = tf.cast(row[\"label\"], tf.float32)\n",
    "    return image, label\n",
    "\n",
    "batch_size = 32\n",
    "dataset = dataset.map(convert).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_generator(latent_dimension):\n",
    "\n",
    "    # 조건 서브 네트워크 : 조건을 히든 표현으로 인코딩\n",
    "    condition = tf.keras.layers.Input((1,))\n",
    "    net = tf.keras.layers.Dense(32, activation=tf.nn.elu)(condition)\n",
    "    net = tf.keras.layers.Dense(64, activation=tf.nn.elu)(net)\n",
    "\n",
    "    # 히든 조건 표현을 노이즈와 업샘플에 연결\n",
    "    noise = tf.keras.layers.Input(latent_dimension)\n",
    "    inputs = tf.keras.layers.Concatenate()([noise, net])\n",
    "\n",
    "    # Convert inputs from (batch_size, latent_dimension + 1)\n",
    "    # (batch_size, latent_dimenstion _ 1)인 inputs를\n",
    "    # 컨볼루션을 사용할 수 있는 4차원 텐서로 변경\n",
    "    inputs = tf.keras.layers.Reshape((1, 1, inputs.shape[-1]))(inputs)\n",
    "\n",
    "    depth = 128\n",
    "    kernel_size = 5\n",
    "    net = tf.keras.layers.Conv2DTranspose(\n",
    "        depth, kernel_size, padding=\"valid\", strides=1, activation=tf.nn.relu\n",
    "    )(\n",
    "        inputs\n",
    "    )  # 5x5\n",
    "    net = tf.keras.layers.Conv2DTranspose(\n",
    "        depth // 2, kernel_size, padding=\"valid\", strides=2, activation=tf.nn.relu\n",
    "    )(\n",
    "        net\n",
    "    )  # 13x13\n",
    "    net = tf.keras.layers.Conv2DTranspose(\n",
    "        depth // 4,\n",
    "        kernel_size,\n",
    "        padding=\"valid\",\n",
    "        strides=2,\n",
    "        activation=tf.nn.relu,\n",
    "        use_bias=False,\n",
    "    )(\n",
    "        net\n",
    "    )  # 29x29\n",
    "    # 28x28x1 출력을 얻기 위해 2x2 커널과의 표준 컨볼루션\n",
    "    # 이미지가 [0, 1] 범위에 있기 때문에 출력은 sigmoid를 사용한다.\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        1, 2, padding=\"valid\", strides=1, activation=tf.nn.sigmoid, use_bias=False\n",
    "    )(net)\n",
    "    model = tf.keras.Model(inputs=[noise, condition], outputs=net)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_discriminator():\n",
    "    # 인코더 서브네트워크 : 피처 벡터를 얻는 피처 추출기\n",
    "    image = tf.keras.layers.Input((28, 28, 1))\n",
    "    depth = 32\n",
    "    kernel_size = 3\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        depth, kernel_size, padding=\"same\", strides=2, activation=tf.nn.relu\n",
    "    )(\n",
    "        image\n",
    "    )  # 14x14x32\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        depth * 2, kernel_size, padding=\"same\", strides=2, activation=tf.nn.relu\n",
    "    )(\n",
    "        net\n",
    "    )  # 7x7x64\n",
    "\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        depth * 3, kernel_size, padding=\"same\", strides=2, activation=tf.nn.relu\n",
    "    )(\n",
    "        net\n",
    "    )  # 4x4x96\n",
    "\n",
    "    feature_vector = tf.keras.layers.Flatten()(net)  # 4*4*96\n",
    "\n",
    "    # 조건에 관한 히든 표현 만들기\n",
    "    condition = tf.keras.layers.Input((1,))\n",
    "    hidden = tf.keras.layers.Dense(32, activation=tf.nn.elu)(condition)\n",
    "    hidden = tf.keras.layers.Dense(64, activation=tf.nn.elu)(hidden)\n",
    "\n",
    "    # 피처 벡터와 히든 레이블 표현 연결\n",
    "    out = tf.keras.layers.Concatenate()([feature_vector, hidden])\n",
    "\n",
    "    # 단일 선형 뉴런으로 이뤄진 최종 분류 레이어 추가\n",
    "    out = tf.keras.layers.Dense(128, activation=tf.nn.relu)(out)\n",
    "    out = tf.keras.layers.Dense(1)(out)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[image, condition], outputs=out)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "def d_loss(d_real, d_fake):\n",
    "    \"\"\"판별기 손실함수\"\"\"\n",
    "    return bce(tf.ones_like(d_real), d_real) + bce(tf.zeros_like(d_fake), d_fake)\n",
    "\n",
    "\n",
    "def g_loss(generated_output):\n",
    "    \"\"\"생성기 손실함수\"\"\"\n",
    "    return bce(tf.ones_like(generated_output), generated_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "latent_dimension = 100\n",
    "G = get_generator(latent_dimension)\n",
    "D = get_discriminator()\n",
    "\n",
    "def train():\n",
    "    # 옵티마이저 및 학습 연산을 정의한다.\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(image, label):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            noise_vector = tf.random.normal(\n",
    "                mean=0, stddev=1, shape=(image.shape[0], latent_dimension)\n",
    "            )\n",
    "            # 생성기에서 샘플링\n",
    "            fake_data = G([noise_vector, label])\n",
    "            # D 손실 게산\n",
    "            d_fake_data = D([fake_data, label])\n",
    "            d_real_data = D([image, label])\n",
    "\n",
    "            d_loss_value = d_loss(d_real_data, d_fake_data)\n",
    "            # G 손실 계산\n",
    "            g_loss_value = g_loss(d_fake_data)\n",
    "        # 이제 손실을 계산했으므로 그래디언트를 계산하고\n",
    "        # 네트워크를 최적화할 수 있다.\n",
    "        d_gradients = tape.gradient(d_loss_value, D.trainable_variables)\n",
    "        g_gradients = tape.gradient(g_loss_value, G.trainable_variables)\n",
    "        # 테이프를 영구로 정의했기 때문에 테이프 삭제\n",
    "        del tape\n",
    "\n",
    "        optimizer.apply_gradients(zip(d_gradients, D.trainable_variables))\n",
    "        optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))\n",
    "        return g_loss_value, d_loss_value, fake_data[0], label[0]\n",
    "\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        for image, label in dataset:\n",
    "            g_loss_value, d_loss_value, generated, condition = train_step(image, label)\n",
    "\n",
    "        print(\"epoch \", epoch, \"complete\")\n",
    "        print(\"loss:\", g_loss_value, \"d_loss: \", d_loss_value)\n",
    "        print(\n",
    "            \"condition \",\n",
    "            info.features[\"label\"].int2str(\n",
    "                tf.squeeze(tf.cast(condition, tf.int32)).numpy()\n",
    "            ),\n",
    "        )\n",
    "        plt.imshow(tf.squeeze(generated).numpy(), cmap=\"gray\")\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}